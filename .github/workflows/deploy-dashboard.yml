name: Deploy AI News Dashboard

on:
  schedule:
    # æ¯æ—¥ æ—¥æœ¬æ™‚é–“ 8:00 (UTC 23:00) ã«å®Ÿè¡Œ
    - cron: '0 23 * * *'
  workflow_dispatch:
    # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
  push:
    branches: [ main ]
    paths:
      - 'ai_news_*.json'
      - 'docs/**'

permissions:
  contents: read
  pages: write
  id-token: write
  actions: read

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

# Set default environment
env:
  # Default to test mode to avoid API costs in CI
  TEST_MODE: true

jobs:
  # Data collection and generation job
  collect-and-generate:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests feedparser anthropic python-dotenv markdown2 jinja2
        
    - name: Run AI news collection (production only)
      if: github.event_name == 'schedule' && github.ref == 'refs/heads/main'
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
        SMTP_PORT: ${{ secrets.SMTP_PORT }}
        EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        RECIPIENT_EMAILS: ${{ secrets.RECIPIENT_EMAILS }}
        TEST_MODE: false
      run: |
        python ai_news_collector.py
        
    - name: Generate test data (for testing/manual runs)
      if: github.event_name != 'schedule' || github.ref != 'refs/heads/main'
      run: |
        # Create some test data if no JSON files exist
        python -c "
        import os, json, sys
        from datetime import datetime
        from ai_news_collector import AINewsCollector
        
        # Check if any JSON files exist
        json_files = [f for f in os.listdir('.') if f.startswith('ai_news_') and f.endswith('.json')]
        if not json_files:
            print('No existing JSON files found, creating test data...')
            collector = AINewsCollector('', test_mode=True)
            summary = collector.run_daily_collection()
            print('Test data created successfully')
        else:
            print(f'Found {len(json_files)} existing JSON files')
        "
        
    - name: Generate dashboard data
      run: |
        python -c "
        from ai_news_collector import AINewsCollector
        collector = AINewsCollector('dummy', test_mode=True)
        collector.generate_dashboard_data()
        "
    
    - name: Verify generated files
      run: |
        echo "ğŸ“ Listing docs directory:"
        ls -la docs/
        echo ""
        echo "ğŸ“„ Checking required files:"
        
        if [ -f "docs/index.html" ]; then
          echo "âœ… index.html exists"
        else
          echo "âŒ index.html missing"
          exit 1
        fi
        
        if [ -f "docs/data/aggregated_news.json" ]; then
          echo "âœ… aggregated_news.json exists"
          echo "ğŸ“Š Data summary:"
          python -c "
          import json
          with open('docs/data/aggregated_news.json', 'r') as f:
              data = json.load(f)
          print(f'  - Total summaries: {data.get(\"total_summaries\", 0)}')
          print(f'  - Total news items: {data.get(\"total_news_items\", 0)}')
          print(f'  - Generated at: {data.get(\"generated_at\", \"N/A\")}')
          "
        else
          echo "âŒ aggregated_news.json missing"
          exit 1
        fi
        
        echo "ğŸ‰ All required files are present"
        
    - name: Setup Pages
      uses: actions/configure-pages@v4
      
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: ./docs

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4

  # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¸ãƒ§ãƒ–ï¼ˆå®Ÿéš›ã®APIå‘¼ã³å‡ºã—ãªã—ï¼‰  
  test-generation:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests feedparser anthropic python-dotenv markdown2 jinja2
        
    - name: Test dashboard data generation
      run: |
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        python -c "
        from ai_news_collector import AINewsCollector
        collector = AINewsCollector('', test_mode=True)
        summary = collector.run_daily_collection()
        collector.generate_dashboard_data()
        print('âœ… Dashboard generation test passed')
        "
        
    - name: Verify generated files
      run: |
        if [ -f "docs/data/aggregated_news.json" ]; then
          echo "âœ… aggregated_news.json generated successfully"
          echo "File size: $(wc -c < docs/data/aggregated_news.json) bytes"
        else
          echo "âŒ aggregated_news.json not found"
          exit 1
        fi
        
        if [ -f "docs/index.html" ]; then
          echo "âœ… index.html exists"
        else
          echo "âŒ index.html not found"
          exit 1
        fi