name: Deploy AI News Dashboard

on:
  schedule:
    # ÊØéÊó• Êó•Êú¨ÊôÇÈñì 8:00 (UTC 23:00) „Å´ÂÆüË°å
    - cron: '0 23 * * *'
  workflow_dispatch:
    # ÊâãÂãïÂÆüË°å„ÇÇÂèØËÉΩ
  push:
    branches: [ main ]
    paths:
      - 'ai_news_*.json'
      - 'docs/**'

permissions:
  contents: read
  pages: write
  id-token: write
  actions: read

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

# Set default environment
env:
  # Default to test mode to avoid API costs in CI
  TEST_MODE: true

jobs:
  # Data collection and generation job
  collect-and-generate:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests feedparser anthropic python-dotenv markdown2 jinja2
        
    - name: Run AI news collection (production only)
      if: github.event_name == 'schedule' && github.ref == 'refs/heads/main'
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
        SMTP_PORT: ${{ secrets.SMTP_PORT }}
        EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        RECIPIENT_EMAILS: ${{ secrets.RECIPIENT_EMAILS }}
        TEST_MODE: false
      run: |
        python ai_news_collector.py
        
    - name: Generate test data (for testing/manual runs)
      if: github.event_name != 'schedule' || github.ref != 'refs/heads/main'
      run: |
        # Create some test data if no JSON files exist
        python -c "
        import os, json, sys
        from datetime import datetime
        from ai_news_collector import AINewsCollector
        
        # Check if any JSON files exist
        json_files = [f for f in os.listdir('.') if f.startswith('ai_news_') and f.endswith('.json')]
        if not json_files:
            print('No existing JSON files found, creating test data...')
            collector = AINewsCollector('', test_mode=True)
            summary = collector.run_daily_collection()
            print('Test data created successfully')
        else:
            print(f'Found {len(json_files)} existing JSON files')
        "
        
    - name: Generate dashboard data
      run: |
        python -c "
        from ai_news_collector import AINewsCollector
        collector = AINewsCollector('dummy', test_mode=True)
        collector.generate_dashboard_data()
        "
    
    - name: Verify generated files
      run: |
        echo "üìÅ Listing docs directory:"
        ls -la docs/
        echo ""
        echo "üìÑ Checking required files:"
        
        if [ -f "docs/index.html" ]; then
          echo "‚úÖ index.html exists"
        else
          echo "‚ùå index.html missing"
          exit 1
        fi
        
        if [ -f "docs/data/aggregated_news.json" ]; then
          echo "‚úÖ aggregated_news.json exists"
          echo "üìä Data summary:"
          python << 'EOF'
          import json
          with open('docs/data/aggregated_news.json', 'r') as f:
              data = json.load(f)
          print(f'  - Total summaries: {data.get("total_summaries", 0)}')
          print(f'  - Total news items: {data.get("total_news_items", 0)}')
          print(f'  - Generated at: {data.get("generated_at", "N/A")}')
          EOF
        else
          echo "‚ùå aggregated_news.json missing"
          exit 1
        fi
        
        echo "üéâ All required files are present"
        
    - name: Setup Pages
      uses: actions/configure-pages@v4
      
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: ./docs

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4

  # „ÉÜ„Çπ„ÉàÁî®„ÅÆ„Ç∏„Éß„ÉñÔºàÂÆüÈöõ„ÅÆAPIÂëº„Å≥Âá∫„Åó„Å™„ÅóÔºâ  
  test-generation:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests feedparser anthropic python-dotenv markdown2 jinja2
        
    - name: Test dashboard data generation
      run: |
        # „ÉÜ„Çπ„Éà„É¢„Éº„Éâ„Åß„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ„Éá„Éº„Çø„ÇíÁîüÊàê
        python -c "
        from ai_news_collector import AINewsCollector
        collector = AINewsCollector('', test_mode=True)
        summary = collector.run_daily_collection()
        collector.generate_dashboard_data()
        print('‚úÖ Dashboard generation test passed')
        "
        
    - name: Verify generated files
      run: |
        if [ -f "docs/data/aggregated_news.json" ]; then
          echo "‚úÖ aggregated_news.json generated successfully"
          echo "File size: $(wc -c < docs/data/aggregated_news.json) bytes"
        else
          echo "‚ùå aggregated_news.json not found"
          exit 1
        fi
        
        if [ -f "docs/index.html" ]; then
          echo "‚úÖ index.html exists"
        else
          echo "‚ùå index.html not found"
          exit 1
        fi